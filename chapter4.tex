\chapter{Marco Aplicativo}

\par En la investigación presentada se destaco la importancia de realizar pruebas de los sistemas de computo antes, durante y después de su desarrollo, los beneficios y dificultades que conlleva el despliegue de una nube híbrida, así como la relevancia de la inyección de fallas y la tendencia actual de este tipo de actividades de pruebas, debido a su importancia en los sistemas para mejorar el comportamiento de estos en caso de fallas.\\
\par Se planteo el desarrollo de un sistema automatizado con herramientas previamente definidas y comparadas, para obtener un entorno de pruebas e inyectar fallas a un clúster de Kubernetes, posteriormente con la respuesta obtenida podremos comparar el comportamiento del clúster al sufrir la falla con un estado óptimo previamente capturado, y establecer la respuesta del sistema a la falla tratada. Se utilizo Ansible para la automatización de las pruebas y así el usuario que utilice el sistema pueda escoger de manera controlada las fallas que desea inyectar. Con la ayuda de Minikube se desplegó un clúster de Kubernetes con un único nodo. Se despliega el clúster de Kurbenetes haciendo uso del container runtime Dockers para el despliegue de los Pods. El uso de estas herramientas sobre otras de similar propósito es respaldado por el hecho que son ampliamente utilizadas, son open source, existe el fácil acceso a la documentación y se posee conocimiento previo en el uso de estas.\\
%%%%%%%%%%%
\section{Objetivos}\label{sec:41}
\par Para el trabajo especial de grado se presentaron los siguientes objetivos:

%%%%%%%%%%%
\subsection{Objetivo General}


\par Estudiar la respuesta de un cluster de Kubernetes a fallas controladas en recursos de red, procesamiento y almacenamiento.

%%%%%%%%%%%
\subsection{Objetivos Específicos}
\begin{itemize}    
    \item Implementar un entorno básico que permita la ejecución de pruebas de inyección de fallas en un cluster de Kubernetes basadas en colecciones y roles de Ansible.
    \item Diseñar pruebas de inyección de fallas para causar interrupciones de servicio en un cluster de Kubernetes.
    \item Aplicar pruebas de inyección de fallas basadas en colecciones de Ansible para:
    \begin{itemize}
        \item Simular sobrecarga de CPU.
        \item Simular saturación de disco. 
        \item Introducir sobrecarga en las interfaces de red.
        \item Introducir latencia en la comunicación entre aplicaciones.
    \end{itemize}
    \item Caracterizar el comportamiento del cluster de Kubernetes en respuesta a la inyección de las fallas consideradas.
    \item Generar los resultados de las pruebas de inyección de fallas:
    \begin{itemize}
        \item Determinar si el sistema es capaz de recuperarse.
        \item Evaluar el posible tiempo de recuperación.
        \item Identificar, cuantificar y recolectar datos en caso de perdida de paquetes.
    \end{itemize}
\end{itemize}
%%%%%%%%%%%
\section{Metodología para el Desarrollo}


\par Las metodologías ágiles son ampliamente utilizadas en las operaciones de desarrollo por muchas organizaciones en la actualidad, su utilidad puede ser aplicada a la implementación de pruebas de inyección de fallas.\\ %\cite{LIB03}
\par En este se selecciono y aplico una metodología de desarrollo ágil, con las respectivas modificaciones que se mencionan posteriormente, con el fin de fomentar el proyecto. De las metodologías ágiles se selecciono Kanban, ya que ella fue la que mejor se adapto a los requerimientos de los experimentos de inyección de fallas a realizados. Su similar simplicidad con XP y uso en la actualidad en el desarrollo de software justifica el uso de Kanban, a su vez la carencia de tener que rellenar roles específicos y realizar eventos, lo ubica por encima sobre Scrum para su uso en el proyecto. La metodología Kanban, tiene principio y características  que justifican su utilización en el proyecto, entre los que destacan:
\begin{itemize}
    \item Flexibilidad en su aplicación: como marco de trabajo, Kanban es flexible y solo deben seguirse sus lineamientos y principios, en ningún caso limita las herramientas que se pueden utilizar, brindando notable independencia en el trabajo al equipo.
    \item Simplicidad: entre los mayores beneficios que tiene Kanban es su simplicidad, ya que contiene relativamente pocos roles a llenar y sólo requiere que se implementen unos pocos artefactos para almacenar la información necesaria y atender algunos eventos.
    \item Amplia flexibilidad a los cambios: Kanban acepta la posibilidad de modificaciones simples en su proceso y en las prioridades de desarrollo de éstos durante alguna iteración.
    \item Eficiencia: Kanban permite al equipo auto-organizarse y al integrar un diseño simple, permite incrementar la eficiencia del equipo de trabajo.
    \item Trabajo en equipo: el trabajo en equipo es aceptado en el método Kanban, que permite que exista una retroalimentación, mejorando la comunicación y optimizando el uso del tiempo.
\end{itemize} 
\par El marco de trabajo Kanban requirió de la siguiente modificación para adaptarse a las necesidades del proyecto:
\begin{itemize}
    \item Documentación y análisis de resultados: aunque muchos procesos ágiles como Kanban contemplan la documentación del trabajo mediante ciertos artefactos, ellos no inducen la recopilación de información de manera exhaustiva. Para poder adaptar este marco a nuestras necesidades de conveniente gestión del conocimiento, es necesario reunir y documentar toda la información posible en cada una de las etapas, analizar los resultados y compararlos con estados estables y/o anteriores. 
\end{itemize}
 
%%%%%%%%%%%
\section{Alcance}


\par En la actualidad, las organizaciones sin importar su tamaño, para asegurar un servicio estable y confiable requieren probar la fiabilidad de su entorno de cómputo híbrido en sus operaciones de desarrollo. Este proyecto propone estudiar la respuesta de un cluster de Kubernetes a fallas controladas en recursos de red, procesamiento y almacenamiento. Específicamente se consider\'o la inyecci\'on de las siguientes fallas: i) estr\'es por CPU; ii) estr\'es por latencia; iii) estr\'es por memoria RAM y iv) estr\'es por disco; y se evaluó el efecto de cada una de ellas por separado en un entorno de Kuberenetes con deployments de dos replicas. Estas son las fallas que comúnmente pueden afectar la calidad de servicio en sistemas desplegados en una red, o mas a\'un, en la internet, donde m\'ultiples usuarios intentan acceder a un recurso, aumentando la carga del sistema, y as\'i el uso de los recursos. Se realiza con dos replicas para estudiar el comportamiento de Kubernetes en el caso de poseer un pod ``sano'' y uno ``enfermo'' y en el caso de que ambas replicas se encuentran afectadas. \\ %(insertar justificacion de pq esas fallas y porque dos replicas nada mas). \\  

% \par El estudio está dirigido a aquellas organizaciones que deseen implementar experimentos de inyección de fallas en Kubernetes, utilizando herramientas que pueden ser obtenidas con facilidad y a su vez probar la capacidad de sus servicios, en caso de eventos indeseables a lo largo de su desarrollo. \\

\par El estudio está dirigido a explorar la implementación de experimentos de inyección de fallas en Kubernetes, utilizando herramientas que pueden ser obtenidas con facilidad y propiciando resultados preliminares útiles para los testers en caso de eventos indeseables a lo largo del desarrollo. Estos resultados preliminares son una primera etapa importante en estudios actuales y para futuros desarrollos mas completos y complejos dirigidos a la evaluación, análisis y cuantificación de fallas en sistema de computación híbrida. \\

% \par A su vez en el estudio se plantearan ciertas incógnitas sobre como se comporta Kubernetes ante ciertas fallas y se buscara responderlas.

%%%%%%%%%%%
\section{Arquitectura Propuesta}

\par El usuario ejecutara módulos de Ansible, lo cual
desencadenara la ejecución de un código de python en el nodo maestro de Kubernetes y así se inyectaran las fallas, apoyándonos con la API server de Kubernetes para acceder a todo el clúster. En la figura \ref{fig:arq02} se presenta la arquitectura básica propuesta.
\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/arq02.png}
	\caption{Arquitectura de la propuesta para el trabajo de grado.}
	\label{fig:arq02}
\end{figure}

\par Para la implementación anterior se plantea el uso de maquinas virtuales (VM), creando %2 instancias
una (1) instancia EC2 de AWS (Amazon Web Services) debido a que se posee conocimientos sobre este servicio y es de fácil acceso. La m\'aquina se configura con las siguientes características:

\begin{itemize}
    \item Para la instalación de Kubernetes de un solo nodo (Minikube) se configura una EC2 t3a.medium de AWS, con 2 vCPUs AMD EPYC 7000 de 2.5 GHz, 4GB de memoria RAM y sistema operativo Linux Ubuntu 20.04, a su vez se configura un AWS EBS de 8GB SSD para que funcione como la memoria en disco de dicha EC2.
\end{itemize}

\par A su vez fue necesaria la implementación de un ambiente local, en un equipo con capacidades de 32Gb de RAM, CPU de 4 núcleos y disco HDD. Fue configurada una maquina virtual para implementar un ambiente similar a la instancia de pruebas creada en AWS, la cual tiene las siguientes características:
\begin{itemize}
    \item La configuración cuenta también con la instalación de Kubernetes de un solo nodo (Minikube), la VM cuenta con dos 2 núcleos de CPU, a su vez cuenta con 4GB de memoria RAM, sistema operativo Linux Ubuntu 20.04 server, el adaptado de red fue configurado en modo puente (bridge) y cuenta con un almacenamiento de 20GB de disco virtual.
\end{itemize}
%%%%%%%%%%%

\section{Desarrollo de un sistema de inyecci\'on de fallas dirigido a Kubernetes}

\par Para la implementación del entorno y de los test de inyección de fallas, fue necesario realizar las actividades que se expondrán a continuación, que a su vez fueron divididas en subtareas, conforme a lo requerido al marco metodológico Kanban para poder diseñar y desarrollar dichos test. Algunas macro actividades derivan de los objetivos propuestos anteriormente en este capitulo y consistieron en:

\subsection{Implementación y despliegue del entorno de pruebas}

\par Para la implementación y despliegue del entorno de pruebas, propuesto en la arquitectura señalada anteriormente en este cap\'itulo, fue necesario el desarrollo de las tareas que se describen a continuación:\\

\subsubsection{Configuración de maquinas}
\par En lo que se refiere a la configuración de las maquinas necesarias para el desarrollo de este trabajo de investigación, se realizo la configuración de las maquinas expuestas con anterioridad en la sección 4.4 de este cap\'itulo, las cuales comparten características similares respecto a:
\begin{itemize}
    \item La instancia de AWS posee 2 vCPU y la instancia local tiene 2 núcleos de cpu, de 4 que posee el hardware.
    \item Ambas instancias poseen 4GB de memoria Ram configurada.
    \item Fue instalado el sistema operativo Linux Ubuntu 20.04 LTS para sevidores en ambas instancias (El sistema operativo fue seleccionado debido a que era una de las versiones mas actuales al momento de iniciar la investigación, siendo Ubuntu una de las distribuciones mas populares y usadas de Linux). 
\end{itemize}
\par Fue necesario el uso de un hypervisor (capa de software para realizar una virtualización de hardware) para configurar la m\'aquina virtual local. Se utilizo Vmware Workstation 15 Player como el hypervisor de preferencia, aunque otro hypervisor que permita el mismo nivel de configuración y personalizaci\'on de máquinas virtuales puede ser utilizado (como VirtualBox de Oracle), el Workstation 15 Player fue seleccionado solo porque  ya se posee conocimiento previo de esta herramienta.\\

\par Para disco, la m\'aquina local posee 20GB de disco virtual sobre un disco duro HDD, a diferencia de la instancia de AWS que solo se le configuro un EBS de 8GB de SSD.\\

\par En el ambiente local fue necesario la configuración del adaptador de red en modo Bridge para poder asignar a la maquina una dirección ip dentro de una red local para las pruebas, lo que permitió el fácil acceso al equipo a través de SSH, para la ejecución de comandos en esta maquina. El resumen de la configuración de la m\'aquina virtual local se puede observar en la imagen \ref{fig:vm01}, todos los demás aspectos de la configuración del hardware se aceptaron por defecto  de la herramienta de virtualizaci\'on.

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.70\columnwidth]{images/vm01.PNG}
	\caption{Arquitectura de la propuesta para el trabajo de grado.}
	\label{fig:vm01}
\end{figure}

\subsubsection{Instalación de herramientas: Minikube}

\par Las maquinas previamente mencionadas fueron configuradas con los requerimientos mínimos necesarios para la instalación de Minikube (Kubernetes de un solo nodo), también es necesario un container runtime como Docker (o similarmente compatible) o un entorno de máquina virtual. Para la instalación de Minikube se realizaron los siguientes pasos (todos los comandos son para el sistema operativo Linux Ubuntu 20.04 LTS server, para otros sistemas usar el comando de función similar):
\begin{enumerate}
    \item Se instala el container runtime (en este caso Docker), para este despliegue se realizo lo siguiente:
    \begin{itemize}
        \item Se actualiza la lista de paquetes existentes, usando el manejador de paquetes apt de Ubuntu:\begin{itemize}
            \item \textbf{sudo apt update}
        \end{itemize}
        \item Se instala algunos paquetes de requisitos previos que permitan a apt usar paquetes a través de HTTPS:
        \begin{itemize}
            \item \textbf{sudo apt install apt-transport-https ca-certificates curl software-properties-common}
        \end{itemize}
        \item Se añade la clave de GPG para el repositorio oficial de Docker en su sistema, tranferimos la llave desde curl que es una herramienta para tranferir data desde un servidor o a un servidor (con las banderas -fsSL, f para que en caso de falla no proporcione la salida, s para que no proporcione ningún mensaje del progreso, S solo despliegue un mensaje de error y L para seguir a la nueva ubicación en caso de que esta haya cambiado):
        \begin{itemize}
            \item \textbf{curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -}
        \end{itemize}
        \item Se agrega el repositorio de Docker a las fuentes de apt:
        \begin{itemize}
            \item \textbf{sudo add-apt-repository ``deb [arch=amd64]\\ https://download.docker.com/linux/ubuntu focal stable''}
        \end{itemize}
        \item Se actualiza la lista de paquetes de nuevo con el repositorio de Docker agregado:
        \begin{itemize}
            \item \textbf{sudo apt update}
        \end{itemize}
        \item Se verifica que Docker se va a instalar desde el repositorio agregado con el comando:
        \begin{itemize}
            \item \textbf{apt-cache policy docker-ce}
        \end{itemize}
        \item Y se procede a instalar Docker con apt:
        \begin{itemize}
            \item \textbf{sudo apt install docker-ce}
        \end{itemize}
        \item Si se desea se puede verificar que Docker se instalo y esta en funcionamiento con:
        \begin{itemize}
            \item \textbf{sudo systemctl status docker}
        \end{itemize}
    \end{itemize}
    \item Antes de instalar Minikube, se instala el cliente de Kubernetes o kubectl a continuación:
    \begin{itemize}
        \item Se actualiza el repositorio apt:
        \begin{itemize}
            \item \textbf{sudo apt-get update}
        \end{itemize}
        \item Y se instalan los paquetes necesarios para usar el repositorio de Kubernetes en apt:
        \begin{itemize}
            \item \textbf{sudo apt-get install -y apt-transport-https ca-certificates curl}
        \end{itemize}
        \item Se descarga la llave de Google Cloud con curl:
        \begin{itemize}
            \item \textbf{sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg \\https://packages.cloud.google.com/apt/doc/apt-key.gpg}
        \end{itemize}
        \item Luego se añade el repositorio de Kubernetes a apt:
        \begin{itemize}
            \item \textbf{echo ``deb[signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg]\\ https://apt.kubernetes.io/ kubernetes-xenial main'' | sudo tee\\ /etc/apt/sources.list.d/kubernetes.list}
        \end{itemize}
        \item Se vuelve a actualizar apt:
        \begin{itemize}
            \item \textbf{sudo apt-get update}
        \end{itemize}
        \item Para instalar kubectl con apt:
        \begin{itemize}
            \item \textbf{sudo apt-get install -y kubectl}
        \end{itemize}
        \item Se verifica la instalación de kubectl:
        \begin{itemize}
            \item \textbf{kubectl version --client}
        \end{itemize}
    \end{itemize}
    \item Una vez instalado Docker y kubectl, se procede a realizar la instalacion de Minikube, el cual requiere que el equipo tenga por lo menos las siguientes características:
    \begin{itemize}
        \item 2 CPUs o mas.
        \item 2GB de memoria RAM o mas.
    \end{itemize}
    \item Luego se procede a obtener la descarga binaria de Minikube haciendo uso de curl (de nuevo con la bandera L para seguir a la ubicación y la bandera O para escribir el archivo remoto obtenido en un archivo local):
    \begin{itemize}
        \item \textbf{curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64}
    \end{itemize}
    \item Se instala Minikube con el siguiente comando: 
    \begin{itemize}
        \item \textbf{sudo install minikube-linux-amd64 /usr/local/bin/minikube}
    \end{itemize}
    \item Se inicia Minikube con los siguientes comandos:
    \begin{itemize}
        \item Si no se tiene acceso root: 
        %--driver=docker se usa en el primer inicio en caso de que se requiera especificar el driver de virtualizaci\'on, y se usa Docker debido a que es uno de los driver que pueden ser utilizados sin ser root
        \begin{itemize}
            \item \textbf{minikube start --drive=docker}
        \end{itemize}
        \item En caso de querer iniciar minikube con acceso root: 
        %en este comando no se especifica driver debido a que root no lo necesita y se asigna el apiserver a localhost
        \begin{itemize}
            \item \textbf{sudo minikube start --vm-driver=none --apiserver-ips 127.0.0.1 --apiserver-name localhost}
        \end{itemize}
    \end{itemize}
\end{enumerate}
\par Al culminar de realizar todos los pasos, se obtiene un instalación de Minikube con lo necesario para el depliegue de pods.


\subsubsection{Instalación de herramientas: Ansible}

\par Para la inyección de las fallas en el ambiente de Kubernetes de un solo nodo previamente instalado siguiendo los pasos anteriores, se propuso el uso de la herramienta de configuración  Ansible. Esta herramienta fue utilizada para la inyección de fallas y aplicar las pruebas basadas en colecciones de Ansible. Para poder instalar la herramienta se realizaron los siguientes pasos:
\begin{enumerate}
    \item Se inicia actualizando apt:
    \begin{itemize}
        \item \textbf{sudo apt update}
    \end{itemize}
    \item Se instala el archivo de paquetes personal o PPA, este software proporciona una abstracción de los repositorios de apt utilizados y permite administrar fácilmente la distribución y las fuentes de software de proveedores de software independientes:
    \begin{itemize}
        \item \textbf{sudo apt install software-properties-common}
    \end{itemize}
    \item Luego se agrega el repositorio de Ansible y actualiza el PPA:
    \begin{itemize}
        \item \textbf{sudo add-apt-repository --yes --update ppa:ansible/ansible}
    \end{itemize}
    \item Finalizar instalando Ansible con el comando:
    \begin{itemize}
        \item \textbf{sudo apt install ansible}
    \end{itemize}
\end{enumerate}

\par Después de ejecutar todos estos comandos, el ambiente deberia estar configura con todas las herramientas propuestas en la arquitectura.

\subsection{Diseño de test de inyección}
\par Al haber implementado el entorno de pruebas basado en tecnologías para el despliegue de entornos en la nube, se procedió a el diseño de las pruebas de inyección de fallas necesarias para poder caracterizar y poner a pruebas el ambiente desplegado. Se tomo en consideración para la elaboración de los test, las herramientas utilizadas como Minikube (Kubernetes de un solo nodo) y Ansible, por ello el uso de lenguajes como Python y de archivos de configuración YAML, debido a que estas herramientas proveen una buena integración  a través del uso de APIs y de un DSL. En el diseño de las pruebas se realizaron las siguientes actividades para poder cumplir con lo propuesto:

\subsubsection{Elaboración de Artefactos : Diagrama y especificación de Casos de Uso}
\par Para el desarrollo de los test de inyección de fallas basadas en colecciones y roles de Ansible, sobre un cluster de Kubernetes de un solo nodo se elaboraron los artefactos de casos de uso expuestos a continuación:\\


\par \textbf{Diagrama de Casos de Uso}\\


\par En la figura \ref{fig:uc01} se muestran los casos de uso identificados para el proyecto, con sus respectivas especificaciones:
% \begin{figure}[htpb!]
% 	\centering
% 	\includegraphics[width=0.70\columnwidth]{images/usecase/ucfaultinjectionfinal.png}
% 	\caption{Diagarama de Casos de Uso (UC) para los módulos de inyección de fallas en Ansible.}
% 	\label{fig:uc01}
% \end{figure}

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.75\columnwidth]{images/usecase/ucfaultinjectionF.png}
	\caption{Diagarama de Casos de Uso (UC) para los módulos de inyección de fallas en Ansible.}
	\label{fig:uc01}
\end{figure}

\par A continuación se presentan cada una de las especificaciones de los casos de uso previamente señalados en el diagrama.
\pagebreak

\textbf{Especificaciones de Casos de Uso}\\
% \par\textbf{UCN Eliminar Pod:}

% \begin{table}[htpb!]
% \tiny
% \centering
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{|l|l|l|c|}
% \hline
% \rowcolor[HTML]{38FFF8}
% \textbf{UCN-1}   & \multicolumn{3}{l|}{\cellcolor[HTML]{38FFF8}\textbf{Eliminar Pod}} \\ \hline
% Dependencias     & \multicolumn{3}{l|}{Ninguna.} \\ \hline
% Precondición     & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario posee un ambiente de \\ kubernetes con un nodo de ansible \\ para ejecutar pruebas.\end{tabular}}  \\ \hline
% Descripción      & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El módulo deberá comportarse \\ como se describe en el siguiente caso de uso \\ cuando el usuario desee eliminar uno o \\ varios Pods.\end{tabular}} \\ \hline
% Secuencia normal & Paso & \multicolumn{2}{l|}{Acción} \\ \hline & 1 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario inicia la ejecución \\ del módulo a través de ansible \\ por consola.\end{tabular}} \\ \hline
%  & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario ejecuta el comando \\ para eliminar pods con los parámetros \\ necesarios como el namespace de pods a \\ eliminar, el nombre de un pod específico \\ a eliminar o si desea eliminar varios pods \\ aleatoriamente y la cantidad de estos.\end{tabular}} \\ \hline
%  & 3 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El modulo elimina el pod especifico o \\ la cantidad de pods requerida de manera \\ aleatoria, siguiendo una distribución \\ poisson por un periodo de tiempo que \\ define  $\lambda$ = 10.\end{tabular}} \\ \hline
%  & 4 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El sistema indica la finalización del módulo \\ sin error.\end{tabular}} \\ \hline
% Postcondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario observa cuales pods \\ fueron eliminados por el módulo.\end{tabular}} \\ \hline
% Excepciones & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
%  & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}Si el usuario introduce algún parámetro \\ de forma errónea.\end{tabular}} \\ \hline
%   &  & E.1 & \begin{tabular}[c]{@{}l@{}}La ejecución del comando indica \\ en rojo por consola la falla del \\ parámetro erróneo.\end{tabular} \\ \hline

% \end{tabular}%
% }
% \end{table}

% \begin{table}[htpb!]
% \tiny
% \centering
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{|l|l|l|c|}
% \hline
% \rowcolor[HTML]{38FFF8} 
% \textbf{UCN-1}   & \multicolumn{3}{l|}{\cellcolor[HTML]{38FFF8}\textbf{Eliminar Pod}} \\ \hline
%  &  & E.2 & El módulo finaliza su ejecución. \\ \hline
%  &  & E.3 & Se cancela el caso de uso. \\ \hline
% Comentarios & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}Los parámetros necesarios para la ejecución \\ son el nombre del namespace,  el nombre del \\ pod a eliminar o “random poisson” \\ (para eliminar aleatoriamente), la cantidad de \\ pods a eliminar (debe ser mayor o igual a 0 \\ para eliminación aleatoria e igual a 1 para un \\ pod específico) y la ubicación del intérprete \\ de python para ansible (la cual en Linux \\ por defecto es /usr/bin/python3).\end{tabular}} \\ \hline
% \end{tabular}%
% }
% \caption{Especificación de UCN1.}
% \label{tab:UCN1}
% \end{table}

\par\textbf{UCN-1 Sobrecargar CPU del Pod:}

\begin{table}[htpb!]
\tiny
\centering
\caption{Especificación de UCN-1.}
\vspace{0.5\baselineskip}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|}
\hline
\rowcolor[HTML]{38FFF8} 
\textbf{UCN-1} & \multicolumn{3}{l|}{\cellcolor[HTML]{38FFF8}\textbf{Sobrecargar CPU del Pod}} \\ \hline
Dependencias & \multicolumn{3}{l|}{Ninguna.} \\ \hline
Precondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario posee un ambiente de kubernetes con un nodo de ansible \\ para ejecutar pruebas.\end{tabular}} \\ \hline
Descripción & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El módulo deberá comportarse como  se describe en el \\ siguiente caso de uso  cuando el usuario desee \\ sobrecargar el CPU  de uno o varios Pods.\end{tabular}} \\ \hline
Secuencia normal & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
 & 1 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario inicia la ejecución del \\ módulo a través de ansible por consola.\end{tabular}} \\ \hline
 & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario ejecuta el comando para sobrecargar \\ el CPU de un pod con los parámetros necesarios \\ como el namespace del pod, el nombre de un pod \\ específico a sobrecargar o si desea sobrecargar varios\\  pods aleatoriamente, la cantidad de estos además de \\ la duración del experimento y la dirección\\ de red del ambiente de Kubernetes.\end{tabular}} \\ \hline
  & 3 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El módulo sobrecarga el CPU del pod \\ seleccionado o sobrecarga el cpu de la \\ cantidad de pods requerida de manera \\ aleatoria, siguiendo una distribución poisson \\ por un periodo de tiempo que define $\lambda$  = 10.\end{tabular}} \\ \hline
 & 4 & \multicolumn{2}{l|}{Se ejecuta el módulo de inyección de forma esperada.} \\ \hline
Postcondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario observa cuáles pods \\ fueron sometidos al módulo de \\ sobrecarga de CPU.\end{tabular}} \\ \hline
Excepciones & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
 & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}Si el usuario introduce algún \\ parámetro de forma errónea.\end{tabular}} \\ \hline
 &  & E.1 & \begin{tabular}[c]{@{}l@{}}La ejecución del comando indica por \\ consola la falla del parámetro erróneo.\end{tabular} \\ \hline
 &  & E.2 & El modulo finaliza su ejecución. \\ \hline
 &  & E.3 & Se cancela el caso de uso. \\ \hline
 Comentarios & \multicolumn{3}{l|}{{\begin{tabular}[c]{@{}l@{}}Los parámetros necesarios para la  ejecución son el nombre del \\ namespace, el nombre del pod a sobrecargar  o “random poisson” \\ (para sobrecargar pods aleatoriamente), la cantidad de pods \\ a sobrecargar (debe ser mayor o igual a 0 para sobrecarga aleatoria \\ e igual a 1 para un pod específico), la duración de ejecución del módulo \\ (experimento) y la ubicación del intérprete de python para ansible \\ (la cual en Linux por defecto es /usr/bin/python3).\end{tabular}}} \\ \hline
\end{tabular}%
}
\label{tab:UCN1}
\end{table}



\vspace{\baselineskip}
\par\textbf{UCN-2 Saturar Disco del Pod:}

\begin{table}[htpb!]
\tiny
\centering
\caption{Especificación de UCN-2.}
\vspace{0.5\baselineskip}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|}
\hline
\rowcolor[HTML]{38FFF8} 
\textbf{UCN-2} & \multicolumn{3}{l|}{\cellcolor[HTML]{38FFF8}\textbf{Saturar Disco del Pod}} \\ \hline
Dependencias & \multicolumn{3}{l|}{Ninguna.} \\ \hline
Precondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario posee un ambiente de \\ kubernetes con un nodo de ansible \\ para ejecutar pruebas.\end{tabular}} \\ \hline
Descripción & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El módulo deberá comportarse como se \\ describe en el siguiente caso de uso cuando \\ el usuario desee saturar el disco de uno o varios Pods.\end{tabular}} \\ \hline
Secuencia normal & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
 & 1 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario inicia la ejecución del módulo \\ a través de ansible por consola.\end{tabular}} \\ \hline
 & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario ejecuta el comando para saturar el disco \\ de un pod con los parámetros necesarios como el \\ namespace del pod, el nombre de un pod específico\\ a saturar el uso del disco o si desea saturar varios pods \\ aleatoriamente, la cantidad de estos, además de la \\ duración del experimento y la dirección\\ de red del ambiente de Kubernetes.\end{tabular}} \\ \hline
 & 3 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El modulo satura la memoria de disco del pod específico, \\ realizando operaciones de lectura/escritura durante el \\ periodo de tiempo.\end{tabular}} \\ \hline
 & 4 & \multicolumn{2}{l|}{Se ejecuta el módulo de inyección de forma esperada.} \\ \hline
Postcondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario observa el incremento en el uso \\ del disco de los pods ocasionado por el módulo \\ de saturar disco.\end{tabular}} \\ \hline
Excepciones & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
 & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}Si el usuario introduce algún parámetro de \\ forma errónea.\end{tabular}} \\ \hline
 &  & E.1 & \begin{tabular}[c]{@{}l@{}}La ejecución del comando indica por consola \\ la falla del parámetro erróneo.\end{tabular} \\ \hline
 &  & E.2 & El modulo finaliza su ejecución. \\ \hline
 &  & E.3 & Se cancela el caso de uso. \\ \hline
Comentarios & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}Los parámetros necesarios para la ejecución son \\ el nombre del namespace, el nombre del pod a ser \\ sometido a la saturación de disco  o “random poisson” \\ (para saturar pods aleatoriamente), la cantidad de pods a \\ saturar (debe ser mayor o igual a 0 para saturar aleatoriamente \\ e igual a 1 para un pod específico), la duración de ejecución \\ del módulo (experimento) y la ubicación del intérprete de python \\ para ansible (la cual en Linux por defecto es /usr/bin/python3).\end{tabular}} \\ \hline
\end{tabular}%
}
\label{tab:UCN2}
\end{table}


\vspace{\baselineskip}
\par\textbf{UCN-3 Introducir latencia en Pod:}

\begin{table}[htpb!]
\tiny
\centering
\caption{Especificación de UCN-3.}
\vspace{0.5\baselineskip}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|}
\hline
\rowcolor[HTML]{38FFF8} 
\textbf{UCN-3} & \multicolumn{3}{l|}{\cellcolor[HTML]{38FFF8}\textbf{Introducir Latencia en Pod}} \\ \hline
Dependencias & \multicolumn{3}{l|}{Ninguna.} \\ \hline
Precondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario posee un ambiente de kubernetes \\ con un nodo de ansible para ejecutar pruebas.\end{tabular}} \\ \hline
Descripción & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El módulo deberá comportarse como se \\ describe en el siguiente caso de uso cuando \\ el usuario desee introducir latencia en una \\ aplicación de uno o varios Pods.\end{tabular}} \\ \hline
Secuencia normal & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
 & 1 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario inicia la ejecución del módulo a través de ansible \\ por consola.\end{tabular}} \\ \hline
 & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario ejecuta el comando para introducir latencia \\ en la interfaz de red de un pod con los parámetros\\  necesarios como el namespace del pod, el nombre de \\ un pod específico a ser sometido al incremento de latencia, \\ que también es introducido por el usuario, o si desea afectar \\ varios pods aleatoriamente, la cantidad de estos, además de \\ la duración del experimento y la dirección\\ de red del ambiente de Kubernetes.\end{tabular}} \\ \hline
  & 3 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El módulo induce latencia en la interfaz \\ de comunicación de pods través de comandos.\end{tabular}} \\ \hline
 & 4 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}Se ejecuta el módulo de inyección de \\ forma esperada.\end{tabular}} \\ \hline
 Postcondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario observa la respuesta de la aplicación \\ de los pods a otras aplicaciones que fue ocasionada\\  por el módulo que introduce latencia en la interfaz \\ de red de los pods.\end{tabular}} \\ \hline
Excepciones & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
 & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}Si el usuario introduce algún parámetro de \\ forma errónea.\end{tabular}} \\ \hline
 &  & E.1 & \begin{tabular}[c]{@{}l@{}}La ejecución del comando indica por consola \\ la falla del parámetro erróneo.\end{tabular} \\ \hline
 &  & E.2 & El modulo finaliza su ejecución. \\ \hline
 &  & E.3 & Se cancela el caso de uso. \\ \hline
Comentarios & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}Los parámetros necesarios para la ejecución son el \\ nombre del namespace, el nombre del pod a ser sometido \\ al incremento de latencia  o “random poisson” (para afectar \\ pods aleatoriamente), la cantidad de pods a afectar (debe ser \\ mayor o igual a 0 para afectar aleatoriamente e igual a 1 para \\ un pod específico), la duración de ejecución del módulo (experimento),  \\ la ubicación del intérprete de python para ansible (la cual en Linux por \\ defecto es /usr/bin/python3) y la “cantidad” de latencia en milisegundos.\end{tabular}} \\ \hline
\end{tabular}%
}
\label{tab:UCN3}
\end{table}

\vspace{\baselineskip}
\par\textbf{UCN-4 Sobrecargar Memoria del Pod:}
\label{sec:expli_test12}
\begin{table}[ht!]
\tiny
\centering
\caption{Especificación de UCN-4.}
\vspace{0.5\baselineskip}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|}
\hline
\rowcolor[HTML]{38FFF8} 
\textbf{UCN-4} & \multicolumn{3}{l|}{\cellcolor[HTML]{38FFF8}\textbf{Sobrecargar Memoria del Pod}} \\ \hline
Dependencias & \multicolumn{3}{l|}{Ninguna.} \\ \hline
Precondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario posee un ambiente de \\ kubernetes con un nodo de ansible \\ para ejecutar pruebas.\end{tabular}} \\ \hline
Descripción & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El módulo deberá comportarse como se \\ describe en el siguiente caso de uso cuando \\ el usuario desee sobrecargar la memoria de uno \\ o varios Pods.\end{tabular}} \\ \hline
Secuencia normal & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
 & 1 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario inicia la ejecución del módulo a través \\ de ansible por consola.\end{tabular}} \\ \hline
 & 2 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario ejecuta el comando para sobrecargar la \\ memoria de un pod con los parámetros necesarios como \\ el namespace del pod, el nombre de un pod específico a \\ sobrecargar o si desea sobrecargar varios pods aleatoriamente, \\  la cantidad de estos, además de la duración del experimento\\ y la dirección de red del ambiente de Kubernetes.\end{tabular}} \\ \hline
  & 3 & \multicolumn{2}{l|}{\begin{tabular}[c]{@{}l@{}}El módulo sobrecarga la memoria del pod seleccionado \\ o sobrecarga la memoria de la cantidad de pods requerida \\ de manera aleatoria, siguiendo una distribución poisson por \\ un periodo de tiempo que define $\lambda$  = 10.\end{tabular}} \\ \hline
 & 4 & \multicolumn{2}{l|}{Se ejecuta el módulo de inyección de forma esperada.} \\ \hline
Postcondición & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}El usuario observa cuales pods fueron sometidos \\ al módulo de sobrecarga de memoria.\end{tabular}} \\ \hline
Excepciones & Paso & \multicolumn{2}{l|}{Acción} \\ \hline
 & 2 & \multicolumn{2}{l|}{Si el usuario introduce algún parámetro de forma errónea.} \\ \hline
 &  & E.1 & \begin{tabular}[c]{@{}l@{}}La ejecución del comando indica por consola la \\ falla del parámetro erróneo.\end{tabular} \\ \hline
 &  & E.2 & El modulo finaliza su ejecución. \\ \hline
 &  & E.3 & Se cancela el caso de uso. \\ \hline
Comentarios & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}Los parámetros necesarios para la ejecución son el nombre \\ del namespace, el nombre del pod a sobrecargar  o “random poisson” \\ (para sobrecargar pods aleatoriamente), la cantidad de pods a sobrecargar \\ (debe ser mayor o igual a 0 para sobrecarga aleatoria e igual a 1 para \\ un pod específico), la duración de ejecución del módulo (experimento) y \\ la ubicación del intérprete de python para ansible (la cual en Linux por \\ defecto es /usr/bin/python3).\end{tabular}} \\ \hline
\end{tabular}%
}
\label{tab:UCN4}
\end{table}



\subsection{Desarrollo de test de inyección}

\subsubsection{Integraci\'on de la herramienta Pystol}
\par Pystol es una herramienta open source creada para demostrar la correlación entre la ejecución de una acción de inyección de fallas y el cambio en el comportamiento del clúster basado en Kubernetes. Se us\'o como base los test de esta herramienta tenia implementados, para el diseño y desarrollo de los test de este trabajo especial. Las pruebas de inyecci\'on de fallas desarrolladas puedan ser intregradas usando Ansible, tambien esta pruebas fueron desarrolladas como contribucion al proyecto opensource de la plataforma Pystol y se espera que en un futuro puedan ser integradas a esta.\\

\par Es necesario ejecutar el siguiente script para Linux (ver Figura \ref{fig:initsh}), a fin de instalar la colecci\'on de los test de inyecci\'on de fallas en Ansible, que se presentan mas adelante en este documento:

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/captures/initsh.PNG}
	\caption{Captura del Script init.sh.}
	\label{fig:initsh}
\end{figure}

\carlos{Al inyectar los fallos debe haber una herramienta  que este generando las peticiones WEB, lectura/escritura, o inyectar trafico. Que herramienta estan utilizando, que parametros de configuracion tiene, por cuanto tiempo estan generando las peticiones?}
 
\carlos{cuantos usuarios concurrentes estan lanzando las peticiones}
 
\carlos{aqui tienen un ejemplo de el criterio para generar el trafico, https://k6.io/docs/test-types/stress-testing/}
 
\carlos{piensen: que algoritmo tiene sentido que el cliente simule? Tiene sentido hacer un stress test, y aparte estamos lanzando Pystol? O buscamos simular el "comportamiento ideal"?}

\subsubsection{Desarrollo de funciones generales}
\par A continuación se explicaran las funciones de código que se reutilizan en cada test de inyección.

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.90\columnwidth]{images/captures/codigo/Capture_get_pod_by_name.PNG}
	\caption{Captura del código de la función get\_pod\_by\_name().}
	\label{fig:codi01}
\end{figure}

\par En la figura \ref{fig:codi01} se muestra el código de la función  $\textbf{get\_pod\_by\_name(namespace, name)}$ la cual retorna la información de un pod a partir de su nombre, dicha función tiene como parámetros el namespace donde se encuentra el pod y su nombre. Ya que se utiliza la API del cliente de Kubernetes para Python se tiene acceso a la función \textbf{read\_namespaced\_pod(name, namespace)} la cual nos retorna el objeto con los detalles del pod. \\

\par Otra función importante de mencionar es \textbf{run\_module} la cual es básicamente el main de los tests de fallas, aquí se leen todos los parámetros recibidos por el modulo (nombre del pod a afectar, tiempo de la prueba, entre otros según el caso), se seleccionan los pod a afectar y es donde se llama a ejecutar la inyección de la falla.\\

\par También se hace gran uso de la herramienta\carlos{que parametros se han utilizado?}\thomas{los parámetros utilizados se describen en detalle cuando explicamos la implementación de cada test por separado puede ver un ejemplo \hyperref[sec:sobrecarga_de_CPU]{AQUI (hacer click)} a partir del tercer párrafo }\textbf{stress-ng} el cual fue diseñado para ejercitar varios subsistemas físicos de una computadora, así como las diversas interfaces del kernel del sistema operativo. La herramienta tiene una amplia gama de diferentes mecanismos de estrés (conocidos como "factores de estrés") de los cuales se hizo uso y se explicaran mas adelante.\\

\subsubsection{Desarrollo de test de inyección de latencia en interfaz de red}

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/captures/codigo/Capture_inyect_latency.PNG}
	\caption{Captura del código de la función inyect\_latency().}
	\label{fig:codi02}
\end{figure}

\par En la figura \ref{fig:codi02} se puede observar la función \textbf{ inyect\_latency(pod, module, duration, latency)} la cual esta encargada de inyectar latencia en la interfaz de red de un pod.\\

\par La función recibe por parámetro los detalles del pod a probar, la instancia del modulo de ansible, la duración de la falla respectivamente y la cantidad en ms de latencia que el usuario quiera inyectar. \\

\par Utilizando el paquete os de Python se logra ejecutar comandos de linux en la maquina que corre el nodo y obtener las respuestas que estos devuelven. \\

\par En los detalles del pod se encuentra un atributo llamado container\_statuses el cual es una lista que tiene un tamaño equivalente al numero de contenedores que se ejecutan en el pod a afectar y en cada posición almacena la información del contenedor. Se realizaran ciclos sobre este arreglo para inyectar la latencia en cada contenedor y luego también para retirar dicho estrés.\\

\par Para inyectar la latencia en un contenedor primero se tiene que saber su ID de proceso, el cual se obtiene con el ejecutando el siguiente comando en el nodo \textbf{docker inspect --format '\{\{.State.Pid \}\}' <ID del contenedor>}, una vez tenemos el ID del proceso podemos ejecutar lo siguiente \textbf{sudo nsenter -t <ID del proceso> \ -n tc qdisc add dev eth0 root netem delay <latency>ms} a continuación una explicación por partes del comando:

\begin{itemize}
        \item nsenter -t <ID del proceso> \ -n: nsenter es una herramienta que permite ejecutar comandos en distintos namespaces de linux, con la bandera -t definimos el namespace objetivo pasándole como argumento el ID del proceso y el -n sin argumento lo que indica es que se utilice la red del proceso que se coloco como objetivo.
        \item tc: Herramienta utilizada para controlar el trafico de red en el kernel de Linux.
        \item qdisc add dev eth0 root: Con el comando qdisc podemos configurar la cola de almacenamiento de una interfaz de red, básicamente en esta sección del comando se esta agregando configuración (definida en el próximo punto) sin clase a la raíz del dispositivo eth0.
        \item netem delay <latency>ms: Esta es la configuración que es agregada a la interfaz, la que se menciono en el punto anterior, netem es un emulador de red que facilita agregar características a los paquetes que salen de una interfaz de red seleccionada, en este caso se agrega un retardo de N (latencia que pasa por parámetro el usuario) en milisegundos.\\
    \end{itemize}
    
\par Una vez todos los contenedores tenga agregada la latencia se esperan N segundos (duración de la falla la cual es agregada por el usuario vía parámetro en el modulo), por ultimo se elimina la configuración que agrega el retardo en la red de todos los contenedores.\\ 

\par Para ejecutar este modulo de inyección de fallas de latencia localmente, se configur\'o el siguiente comando:
\begin{itemize}
    \item \textbf{ansible -m include\_role \ -a `name=pystol.actions.networkstresspod' \ -e `$\{$ \\
    `pystol\_networkstresspod\_namespace': `<Namespace de los Pods>', \\
    `pystol\_networkstresspod\_pod': `<Nombre del Pod o aleatorio>', \\
    `pystol\_networkstresspod\_duration': `<Duración de la Falla', \\
    `pystol\_networkstresspod\_amount': `<Cantidad de Pods>', \\
    `ansible\_python\_interpreter': `/usr/bin/python3', \\
    `pystol\_networkstresspod\_latency': `<Cantidad de Latencia en ms>'$\}$' \ localhost} %\ -vvvv}
\end{itemize}

\subsubsection{Desarrollo de test de inyección de sobrecarga de CPU}
\label{sec:sobrecarga_de_CPU}
\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/captures/codigo/Capture_inyect_cpu.PNG}
	\caption{Captura del código de la función inyect\_cpu().}
	\label{fig:codi03}
\end{figure}

\par En la figura \ref{fig:codi03} se puede observar la función \textbf{ inyect\_cpu(name, namespace, module, duration)} la cual esta encargada de inyectar la sobrecarga de CPU en un pod.\\
\par La función recibe por parámetro el nombre y el namespace del pod, la instancia del modulo de ansible y la duración de la falla respectivamente. \\
\par Inicialmente en esta función se crea una instancia de la API de Kubernetes para Python, luego se revisa si ciertamente existe un pod con el nombre y el namespace recibido por parámetros, a continuación se definen los comandos que se ejecutaran en el pod en los cuales se instala la herramienta stress-ng y se ejecuta la falla con el siguiente comando 
\textbf{stress-ng --cpu 8 --io 4 --vm 2 --vm-bytes 128M --timeout <duration>} a continuación una explicación de lo que significa cada bandera que se utiliza:
\carlos{esto no tiene mucho sentido, la prueba correcta sería, un pod con una aplicacion web, luego generan tráfico simulado con un criterio X, en ese momento lanzan la prueba desde ansible que satura el pod, miden como se comporta la aplicacion web, deja de responder? se crea otro pod?}
\thomas{No comprendemos muy bien en que contexto nos comenta esto, nosotros intentamos responder estas preguntas (deja de responder? se crea otro pod?) pero no en esta sección,  puede ver un ejemplo \hyperref[sec:falla_cpu_exp]{AQUI (hacer click)}, Nunca logramos tumbar el servicio pero si afectar su rendimiento, esto lo comentamos en el ultimo párrafo de las conclusiones}
\begin{itemize}
        \item --cpu 8: Se inician 8 trabajadores que realizaran todos los trabajos de estress de CPU disponibles en stress-ng.
        \item --io 4: Se inician 4 trabajadores que realizan operaciones de entrada y salida en la cache del disco.
        \item --vm 2: Se inician 2 trabajadores que empiezan a hacer operaciones de escritura dentro de la memoria fisica asignada.        
        \item --vm-bytes 128M: Se le asignan 128 megabytes a cada trabajador de la bandera anterior.
        \item --timeout <duration>: Duración de la prueba.\\
    \end{itemize}

\par Por ultimo utilizando \textbf{stream} y \textbf{connect\_get\_namespaced\_pod\_exec} los cuales provienen de la API de Kubernetes, se logran ejecutar en el pod todos los comandos definidos previamente y recibir la respuesta.\\

\par Para ejecutar este modulo de inyección de fallas en CPU localmente, se configur\'o el siguiente comando:
\begin{itemize}
    \item \textbf{ansible -m include\_role \ -a `name=pystol.actions.cpustresspod' \ -e `$\{$ \\   
    `pystol\_cpustresspod\_namespace': `<Namespace de los Pods>',\\
    `pystol\_cpustresspod\_pod': `<Nombre del Pod o aleatorio>',\\
    `pystol\_cpustresspod\_duration': `<Duración de la Falla>',\\
    `pystol\_cpustresspod\_amount': `<Cantidad de Pods>',\\
    `ansible\_python\_interpreter': `/usr/bin/python3'$\}$' \ localhost} % \ -vvvv}
\end{itemize}


\subsubsection{Desarrollo de test de inyección de sobrecarga de Memoria}

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/captures/codigo/Capture_inyect_memory.PNG}
	\caption{Captura del código de la función inyect\_memory().}
	\label{fig:codi04}
\end{figure}

\par En la figura \ref{fig:codi04} se puede observar la función \textbf{ inyect\_memory(name, namespace, module, duration)} la cual esta encargada de inyectar la sobrecarga en la memoria RAM de un pod.\\
\par La función recibe por parámetro el nombre y el namespace del pod, la instancia del modulo de ansible y la duración de la falla respectivamente. \\
\par Inicialmente en esta función se crea una instancia de la API de Kubernetes para Python, luego se revisa si ciertamente existe un pod con el nombre y el namespace recibido por parámetros, a continuación se definen los comandos que se ejecutaran en el pod en los cuales se instala la herramienta stress-ng y se ejecuta la falla con el siguiente comando
\textbf{stress-ng --vm 2 --vm-bytes 2048M --vm-method all -t <duration> } a continuación una explicación de lo que significa cada bandera que se utiliza:
\begin{itemize}
        \item --vm 2: Se inician 2 trabajadores que empiezan a hacer operaciones de escritura dentro de la memoria fisica asignada.        
        \item --vm-bytes 2048M: Se le asignan 2048 megabytes a cada trabajador de la bandera anterior.
        \item --vm-method all: Para que utilice todos los métodos disponibles en stress-ng de pruebas de memoria.
        \item -t <duration>: Duración de la prueba.\\
    \end{itemize}

\par Por ultimo utilizando \textbf{stream} y \textbf{connect\_get\_namespaced\_pod\_exec} los cuales provienen de la API de kubernetes, se logran ejecutar en el pod todos los comandos definidos previamente y recibir la respuesta.\\

\par Para ejecutar este modulo de inyección de fallas en memoria localmente, se configur\'o el siguiente comando:
\begin{itemize}
    \item \textbf{ansible -m include\_role \ -a `name=pystol.actions.memorystresspod' \ -e `$\{$ \\
    `pystol\_memorystresspod\_namespace': `<Namespace de los Pods>', \\
    `pystol\_memorystresspod\_pod': `<Nombre del Pod o aleatorio>', \\
    `pystol\_memorystresspod\_duration': `<Duración de la Falla>', \\
    `pystol\_memorystresspod\_amount': `<Cantidad de Pods>', \\
    `ansible\_python\_interpreter': `/usr/bin/python3'$\}$' \ localhost} %\ -vvvv}
\end{itemize}



\subsubsection{Desarrollo de test de inyección de sobrecarga de Disco}

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/captures/codigo/Capture_inyect_disk.PNG}
	\caption{Captura del código de la función inyect\_disk().}
	\label{fig:codi05}
\end{figure}

\par En la figura \ref{fig:codi05} se puede observar la función \textbf{ inyect\_disk(name, namespace, module, duration)} la cual esta encargada de inyectar la sobrecarga en el disco.\\

\par Este test saturara el disco con una cantidad considerable de operaciones de entrada y salida con lo cual se afectara el rendimiento del mismo, dichas operaciones son sobre un buffer ficticio por lo cual no genera almacenamiento basura. \\

\par La función recibe por parámetro el nombre y el namespace del pod, la instancia del modulo de ansible y la duración de la falla respectivamente. \\

\carlos{que es sobrecarga de disco?}
\thomas{Por su comentario agregamos una breve explicación de que hace la falla, puede verla en el segundo párrafo de esta sección.}

\par Inicialmente en esta función se crea una instancia de la API de Kubernetes para Python, luego se revisa si ciertamente existe un pod con el nombre y el namespace recibido por parámetros, a continuación se definen los comandos que se ejecutaran en el pod en los cuales se instala la herramienta stress-ng y se ejecuta la falla con el siguiente comando
\textbf{stress-ng --hdd 1 --aggressive --timeout <duration> } a continuación una explicación de lo que significa cada bandera que se utiliza:
\begin{itemize}
        \item --hdd 1: Se inicia un trabajador que escribe, lee y elimina archivos temporales en el disco.        
        \item --aggressive: Para que utilice todas las opciones disponibles en stress-ng que realicen operaciones de entrada y salida en el disco.
        \item --timeout <duration>: Duración de la prueba.\\
    \end{itemize}

\par Por ultimo utilizando \textbf{stream} y \textbf{connect\_get\_namespaced\_pod\_exec} los cuales provienen de la API de kubernetes, se logran ejecutar en el pod todos los comandos definidos previamente y recibir la respuesta.\\
\label{sec:expli_test1}
\par Para ejecutar este modulo de inyección de fallas en disco localmente, se configur\'o el siguiente comando:
\begin{itemize}
    \item \textbf{ansible -m include\_role \ -a `name=pystol.actions.diskstresspod' \ -e `$\{$ \\
    `pystol\_diskstresspod\_namespace': `<Namespace de los Pods>', \\
    `pystol\_diskstresspod\_pod': `<Nombre del Pod o aleatorio>', \\
    `pystol\_diskstresspod\_duration': `<Duración de la Falla>', \\
    `pystol\_diskstresspod\_amount': `<Cantidad de Pods>', \\
    `ansible\_python\_interpreter': `/usr/bin/python3'$\}$' \ localhost} %\ -vvvv}
\end{itemize}
\carlos{hace falta una tabla con los parametros de configuracion}
\thomas{Realizamos la tabla \ref{tab:tablaconfdisco}, con el fin de saber si resuelve lo que nos comenta, si la respuesta es satisfactoria procederemos a cambiar la redacción y agregarlo a todas las secciones que lo ameritan.}

\begin{table}[ht!]
\centering
\caption{Parámetros de configuración para el comando de inyección de falla de disco con Ansible.}
\vspace{0.5\baselineskip}
\resizebox{\textwidth}{!}{
\begin{tabular}{|c|c|c|} 
 \hline
 \multicolumn{3}{|c|}{\textbf{Parámetros de Configuración}} \\
 \hline
 \hline
 Parámetro & Variable & Descripción\\
 \hline
 -m & include\_role & Nombre del modulo a ejecutar\\
 \hline
 -a & ‘name=pystol.actions.diskstresspod’ & \begin{tabular}[t]{@{}c@{}}Nombre de la acción del modulo \\ que se desea ejecutar\end{tabular}\\
  \hline
 -e & <Parámetros para la acción de disco> & \begin{tabular}[t]{@{}c@{}}Argumentos extra que recibirá la acción \\ que se ejecutara (definidas en la \\sección de parámetros para la acción de \\ disco de  esta tabla)\end{tabular}\\
 \hline
 \hline
 \multicolumn{3}{|c|}{\textbf{Parámetros para la acción de disco}} \\
 \hline
 \hline
 Parámetro & Variable & Descripción\\
 \hline
 \begin{tabular}[t]{@{}c@{}}pystol\_diskstresspod\\ \_namespace \end{tabular} & <Namespace de los Pods> & \begin{tabular}[t]{@{}c@{}}Identificador del namespace \\ en el cluster que contiene los pods \\ a ser afectados por la falla\end{tabular}\\ \hline
 \begin{tabular}[t]{@{}c@{}}pystol\_diskstresspod\\ \_pod \end{tabular} & <Nombre del Pod o aleatorio> & \begin{tabular}[t]{@{}c@{}}Identificador en el cluster del pod a \\ ejecutar la falla o ‘aleatorio’ para \\ ejecutar en varios pods del \\ namespace aleatoriamente \end{tabular} \\ \hline
 \begin{tabular}[t]{@{}c@{}}pystol\_diskstresspod\\ \_duration \end{tabular} & <Duración de la Falla> & \begin{tabular}[t]{@{}c@{}}Tiempo de duración de la falla en \\ minutos, numero entero > a 0 o \\ por defecto 5 minutos \end{tabular} \\ \hline
 \begin{tabular}[t]{@{}c@{}}pystol\_diskstresspod\\ \_amount \end{tabular} & <Cantidad de Pods> & \begin{tabular}[t]{@{}c@{}} Cantidad de pods a afectar por \\ la falla, numero entero > 0 para \\ afectar dicha cantidad de pods \\ aleatoriamento o 1 si solo se va afectar \\ un pod especifico individual \\ (depende del valor en pystol\\ \_diskstresspod\_pod)  \end{tabular} \\ \hline
 \begin{tabular}[t]{@{}c@{}}ansible\_python\\ \_interpreter \end{tabular} & /usr/bin/python3 & \begin{tabular}[t]{@{}c@{}}Ruta por defecto al directorio \\ donde se encuentra el \\ interprete de python \end{tabular} \\
 \hline
\end{tabular}
}
\label{tab:tablaconfdisco}
\end{table}

\subsection{Implementación y despliegue de herramientas del sistema}
\par Una vez teniendo las pruebas de inyección de fallas y el ambiente de estas implementado, fue necesario el despliegue de pods con características especificas para poder observar y caracterizar el comportamiento del cluster de Kubernetes con un solo nodo; también la obtención de métricas y resultados.\\
\subsubsection{Obtenci\'on de m\'etricas de Kubernetes: metrics-server}

\par Las métricas de uso de los recursos, como la CPU del pod y el uso de la memoria de este, están disponibles en Kubernetes a través de la API de métricas. Un usuario puede acceder a estas métricas directamente con un comando o un controlador en el clúster, por ejemplo el controlador encargado de escalar los pods horizontalmente. Metrics-Server es un agregador de datos de uso de recursos y es un componente a nivel de clúster que periódicamente extrae las métricas de todos los nodos de Kubernetes que ofrece Kubelet. A través de la API de métricas, puede obtener la cantidad de recursos que utiliza actualmente un nodo o un pod determinado, esta API no almacena los valores de las métricas, por lo que no es posible obtener valores de uso históricos sin el uso de herramientas de terceros \cite{WEB03}. Al consultar el servidor por linea de comandos se pueden obtener las siguientes métricas: 
\begin{itemize}
    \item \textbf{CPU:} El uso de CPU se informa como el uso promedio, en núcleos de CPU, durante un período de tiempo, este valor se obtiene tomando una tasa sobre un contador de CPU acumulativo proporcionado por el kernel (tanto en Linux como Windows) y Kubelet elige la ventana de tiempo para el cálculo del valor.
    \item \textbf{Memoria:} La memoria se informa como el \textit{working set} o ``conjunto de trabajo'', en bytes, en el instante en que se recopiló la métrica, el \textit{working set} es la cantidad de memoria en uso que no se puede liberar bajo la presión de la memoria. Sin embargo, el cálculo del conjunto de trabajo varía según el sistema operativo del host y por lo general, se produce una estimación. Incluye toda la memoria anónima (no respaldada en archivos), ya que Kubernetes no admite el swap, la métrica también incluye algo de memoria en caché (respaldada por archivos), porque el sistema operativo del host no siempre puede reclamar dichas páginas.
\end{itemize}

\par Para hacer uso del metrics-server por comandos es necesario realizar los pasos a continuación:
\begin{enumerate}
    \item Se ejecuta el siguiente comando para habilitar el servidor de metricas dentro del cluster (es necesario levantar Minikube):
    \begin{itemize}
        \item \textbf{minikube addons enable metrics-server}
    \end{itemize}
    \item Una vez habilitado metrics-server se puede consultar la ultima medicion realizada con:
    \begin{itemize}
        \item \textbf{kubectl top}
        \item \textbf{kubectl top pods} para obtener los recursos utilizados por los pods.
    \end{itemize}
\end{enumerate}

\subsubsection{Implementación y despliegue de pods: Nginx}

\par A fin de medir los efectos adversos que ocasionan estas fallas y también obtener un estado inicial estable considerable, fueron desplegados deployments con imágenes de contenedor de Nginx. Estos deployment de Nginx fueron usados para proveer un entorno de pruebas comprensible, para así obtener métricas entendibles, antes y después de la ejecución de los experimentos de inyección de fallas.\\

\par Para poder insertar fallas y medir sus resultados fueron desplegados 2 Nginx deployments (uno de control y otro pruebas) cada uno con 2 replicas. Ambos deployments poseen 2 pods activos, también se despliegan dos servicios los cuales prestan los deployments en la red local y son expuestos por un puerto asignado por Kubernetes. 

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/captures/podnginx/second01.PNG}
	\caption{Archivo de despliegue de deployment .YAML (parte\#1).}
	\label{fig:yml01}
\end{figure}

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/captures/podnginx/second02.PNG}
	\caption{Archivo de despliegue de deployment .YAML (parte\#2)}
	\label{fig:yml02}
\end{figure}

\par En las figuras \ref{fig:yml01} y \ref{fig:yml02}, se puede observar el archivo .YAML desarrollado para el despliegue de los deployments de Nginx. En dicho el archivo se puede observar características previamente mencionadas, como la creación de 2 replicas de la imagen de Nginx, también se puede ver la creación del servicio y que cada una de estas replicas posee volúmenes del tipo configMap (el cual no es compartido por ambas replicas). En este archivo se configura el uso de los logs de nginx, realizando el cambio necesario dentro del archivo nginx.conf que se encuentra en el volumen de cada pod. Se habilitan los 2 logs, el \textit{error.log} y el \textit{access.log}, el mas relevante sera el log access, ya que se revisara para obtener los tiempos de respuesta por cada solicitud que realiza un cliente al servicio de los deployment. Se le da formato a \textit{access.log} solicitando las variables requeridas para obtener la métrica deseada (el \textit{request time} o tiempo de solicitud, tiempos de respuesta o response time). Es necesario realizar el comando \textbf{kubectl apply -f <deployFile.YAML>} para que se apliquen los cambios y se desplieguen los deployments necesarios con sus respectivos pods y servicios.\\

\par El deployment de Nginx se encarga de servir una pagina simple, en la cual un usuario puede escribir un URL de una imagen para que la pagina la muestre. El documento HTML para el deployment de pruebas cuenta con un peso total de 17628379 bytes (17MB aproximadamente), ambos pods del deployment se encargan de mostrar el mismo sitio por el servicio asignado.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/captures/podnginx/html01.PNG}
	\caption{Archivo Html par los deployments de Nginx.}
	\label{fig:html01}
\end{figure}

\par Se realizo la inserción de una gran cantidad de comentarios (ver Figura \ref{fig:html01}), para incrementar el peso en almacenamiento de la pagina y obtener valores significativos de tiempos de repuesta medibles, es decir, tiempo de respuesta $\textbf{rt > 0.000}$ cuando un cliente realice una solicitud. Para cambiar el index.html de cada pod se uso el comando \textbf{kubectl cp <htmlFileDrirectory>/<htmlFile> <podIdentifier>:/usr/share/nginx/html/index.html} que copia el archivo del equipo al pod. Una vez copiado se puede acceder a la p\'agina, a través de un navegador en un equipo que se encuentre en la red local, para obtener el URL del servicio se ejecuta el comando \textbf{minikube service <serviceName>}, que en este caso es secondnginx-service debido que este es el que se muestra como ejemplo en el .YAML.\\

\par Cada vez que alguien realiza una petición al servicio, dicha solicitud se ve reflejada en el access log de Nginx, el cual puede ser revisado copiando el archivo desde el pod al equipo realizando \textbf{kubectl cp <podIdentifier>:/var/log/nginx/access.log <directoryForCopy>/access.log}, luego se accede al log con uso de un editor de texto como vim o nano y se pueden observar las metricas de request\_time y response\_time.\\ 

\label{sec:servicio_web}
\par Así fue implementado en su totalidad el ambiente a usar para probar el funcionamiento de los test, así como, los pods para los experimentos y poder medir métricas simples, de fácil lectura. 
%\subsubsection{Depliegue de pods: Prometheus}
%%%%%%%%%%

\subsection{Evaluaci\'on del sistema de fallas desarrollado}

\par El grupo de experimentos a continuación demuestran que las pruebas de inyección de fallas se comportan de la manera esperada.\\ 

\par Cabe destacar que todos los experimentos de esta sección se realizaron en una maquina virtual que utiliza un disco HDD, con dos cores de CPU y 4GB de RAM.\\

\par Para medir objetivamente el desempeño del sistema se  definieron un conjunto de indicadores que permitieron comparar los resultados obtenidos.\\

\par Como el funcionamiento del sistema de inyección de fallas depende de cuatro módulos: latencia, CPU, memoria y disco se utilizaron distintos indicadores para cada prueba, los cuales se explican a continuación:
\begin{itemize}
    \item Latencia: Se utilizo ping para su medición, se expresa en milisegundos (ms) es el tiempo que tardan en comunicarse dos puntos en la red.
    \item Memoria RAM: Se expreso su uso en mebibyte (Mi), su equivalencia en bytes es la siguiente: \[ 1\ mebibyte = 1\ Mi = 2^{20}\ bytes = 1.048.576\ bytes \]
    \item CPU: Se utilizo la unidad de Kubernetes llamada millicpu (m) en el cual se divide un núcleo de CPU en 1000 unidades.
    \item Disco: Se expreso con el porcentaje de operaciones de entrada y salida en disco.
\end{itemize} 

\carlos{todas las tablas de los resultados no tienen sentido, deben mostrar el estado del cluster en funcion del tiempo}
\thomas{Estamos realizando gráficos los cuales tendrán en el eje X el tiempo y en el eje Y la variable a estudiar, esperamos poder tenerlos listo para cada experimento lo antes posible.}
\carlos{RESPONDER PARA CADA PRUEBA:}

\carlos{- Objetivo}
\carlos{- Por que es interesante medir ese aspecto del desempeño del cluster, por ejemplo, por que es interesante medir la latencia}
\thomas{Agregado}

\carlos{- Cual es la duracion de cada prueba? Donde se configura? Como se ejecuta?}
\thomas{con respecto a la duración lo acabamos de agregar; sobre como se ejecuta y como se configura el test lo hablamos en dos lugares distintos 
\hyperref[sec:expli_test12]{AQUI (hacer click) } y \hyperref[sec:expli_test1]{AQUI (hacer click)} de igual manera si hay alguna configuración que haya que destacar (como por ejemplo el ping que se configuro para la prueba) lo estamos agregando.}


\par Se cuantific\'o un estado estable inicial, sobre los pods de un despliegue de control antes de realizar cualquier test, el cual proporciono las siguientes métricas iniciales, sobre ambos pods del deployment:
\begin{table}[ht!]
\centering
\caption{Métricas iniciales Deployment.}
\vspace{0.5\baselineskip}
\begin{tabular}{|c|c|} 
 \hline
 \multicolumn{2}{|c|}{Estado inicial} \\
 \hline
 \hline
 Métrica & Valor(Aprox.)\\
 \hline
 CPU(millicpu) & 0 mCpu\\
 Memoria(mebibytes) & 3 Mi \\
 Uso Disco(\%) & 1.00 \% \\
 Latencia(milisegundos) & 0.045 ms\\
 %Request Time (rt) & 0.492 s\\
 \hline
\end{tabular}
\label{tab:tabla40}
\end{table}

\par Los valores de CPU y Memoria se obtuvieron utilizando la herramienta del metrics-server de Minikube, siendo consultado varias veces antes de los experimentos. Para medir el Request Time o tiempo de solicitud, se accedió al servicio a través de un navegador sin almacenar cache, durante 30 minutos se realizaron dos solicitudes a dicho servicio por minuto, luego se reviso el access.log de ambos pod del deployment y se calculo el promedio de los tiempos de solicitud en dicho log.


\subsubsection{Probando el estrés por CPU}

\carlos{Aqui hace falta una grafica que muestre el uso del CPU en funcion del tiempo, en un estado normal}
\carlos{Aqui hace falta una grafica que muestra el uso del CPU en funcion del tiempo mientras se ejecuta el fault injection}
\thomas{Agregado}

\par Es importante medir el CPU ya que este componente se encarga de procesar todas las instrucciones del computador, leyendo las órdenes y requisitos del sistema operativo, así como las instrucciones de cada uno de los componentes y las aplicaciones. El mal funcionamiento del CPU pondrá en riesgo el rendimiento de todo el sistema, hasta podría ocasionar el apagado del computador.\\

% \par Se probo la inyección de falla al estudiar el uso inicial del CPU en millicpu (antes del estrés) de un pod de Nginx que tiene dos cores de CPU, luego se estreso al agregarle la sobrecarga de CPU y por ultimo se observa el estado (mientras sucede la falla) para compararlo con el inicial y así demostrar que esta funcionando dicha falla.\\

\par Para obtener el indicador en millicpu en cada estado, se utilizo el comando \\ \verb|kubctl top pods| desde la maquina virtual que tiene alojado a Kubernetes, dicho comando básicamente permite ver el consumo de recursos de los pods.\\

% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & CPU(millicpu)\\
%  \hline
%  Inicial & 0\\
%  Falla & 1658\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del uso del CPU en los estados del experimento de estrés por CPU.}
% \label{tab:tabla41}
% \end{table}

\par En la Figura \ref{fig:usocpu01} se presenta la variación del uso del CPU en función del tiempo. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla de CPU. El sistema fue monitorizado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. La figura muestra un tiempo de retardo en la respuesta al estrés de aproximadamente 30 segundos, tanto al inicio como al final, esto posiblemente debido al tiempo de respuesta que toma el servicio de Kubernetes para obtener métricas (metrics-server), cuando va a retornar el snapshot del consumo de recursos del pod. Una vez estabilizado el estrés este alcanza un valor medio de 1809.25m con una desviación estándar igual a 9.23. Y una diferencia de 1809.25m sobre el estado sin estrés.\\

\par Con el resultado se puede observar el aumento sustancial del uso del CPU, el pod afectado durante el estrés esta usando aproximadamente el 90\% del CPU una vez estabilizada la falla, por lo cual esta funcionando correctamente la inyección de fallas.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficaspruebas/usocpu.png}
	\caption{Gráfica del uso del CPU por un pod en función del tiempo durante el experimento.}
	\label{fig:usocpu01}
\end{figure}

\subsubsection{Probando el estrés por latencia}

\carlos{Aqui hace falta una grafica que muestre la latencia en funcion del tiempo, en un estado normal}
\carlos{Aqui hace falta una grafica que muestra la latencia en funcion del tiempo mientras se ejecuta el fault injection}
\thomas{Agregado}

\par Es importante medir la latencia especialmente en sistemas donde la inmediatez con la que nos comunicamos con un servidor es vital para la actividad que estamos realizando. Tener una alta latencia dará como resultado un retardo en las comunicaciones por lo cual afectara el rendimiento del sistema.\\

% \par Se probara la inyección de falla por latencia estudiando el ping inicial (antes del estrés) de un pod de Nginx, luego se estresara al agregarle un ping de 500ms y por ultimo se observara el estado (mientras sucede la falla) para compararlo con el inicial y así demostrar que esta funcionando dicha falla.\\

\par Para obtener el indicador de latencia en cada estado, se utilizo el comando \\ \verb|ping -c 4 <IP del pod afectado>| desde la maquina virtual que tiene alojado a Kubernetes, dicho comando básicamente envía cuatro solicitudes de ICMP hacia la IP del pod afectado y luego muestra las respuesta de cada solicitud en la cual se puede observar el tiempo que tarda cada paquete en llegar a su destino y regresar (latencia en ms).\\
% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Ping(promedio)\\
%  \hline
%  Inicial & 0.055ms\\
%  Falla & 500.5ms\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del ping en los estados del experimento de estrés por latencia.}
% \label{tab:tabla42}
% \end{table}

% \vspace{\baselineskip}

\par En la Figura \ref{fig:ping01} se presenta la variación de la latencia en función del tiempo. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla de latencia. El sistema fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. La figura no muestra ningún tiempo de retardo en la respuesta al estrés en el inicio ni en el final. Una vez estabilizado el estrés la latencia alcanza un valor medio de 500.4ms con una desviación estándar de 0.51. Y una diferencia de 500.35ms sobre el estado sin estrés.\\

\par Con el resultado se puede observar el aumento de 500ms en la latencia en el estado de falla, por lo cual esta funcionando correctamente el estrés por latencia.\\



 \begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficaspruebas/ping.png}
	\caption{Gráfica del incremento de latencia en un pod en función del tiempo durante el experimento.}
	\label{fig:ping01}
\end{figure}

\subsubsection{Probando el estrés por memoria RAM}

\carlos{Aqui hace falta una grafica que muestre el uso de la memoria principal en funcion del tiempo, en un estado normal}
\carlos{Aqui hace falta una grafica que muestra el uso de la ram en funcion del tiempo mientras se ejecuta el fault injection}
\thomas{Agregado}

\par La importancia de medir la memoria RAM radica en que es un componente fundamental para la eficiencia de un sistema computacional, su función principal es almacenar datos e instrucciones para que puedan ser accedidos por otros componentes básicos, de manera que evita que tengan que volver a pasar por el procesador o incluso por la tarjeta gráfica. \\

% \par Se probara la inyección de falla estudiando el uso inicial de memoria RAM en mebibyte (antes del estrés) de un pod de Nginx, luego se estresara al agregarle la sobrecarga de memoria RAM y por ultimo se observara el estado (mientras sucede la falla) para compararlo con el inicial y así demostrar que esta funcionando dicha falla.\\

\par Para obtener el indicador en mebibyte en cada estado, se utilizo el comando \\ \verb|kubctl top pods| desde la maquina virtual que tiene alojado a Kubernetes, dicho comando básicamente permite ver el consumo de recursos de los pods.\\
% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Memoria(mebibytes)\\
%  \hline
%  Inicial & 2\\
%  Falla & 2059\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del porcentaje de uso de la memoria RAM en los estados del experimento de estrés por memoria.}
% \label{tab:tabla43}
% \end{table}

\par En la Figura \ref{fig:usoram01} se presenta la variación del uso de memoria RAM en función del tiempo. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla de RAM. El sistema fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. La figura muestra un tiempo de retardo en la respuesta al estrés de aproximadamente 30 segundos, tanto al inicio como al final, esto posiblemente, al igual que vimos anteriormente es debido al tiempo de respuesta que toma el servicio de Kubernetes para obtener métricas (metrics-server), cuando va a retornar el snapshot del consumo de recursos del pod. Una vez estabilizado el estrés el uso de la memoria RAM alcanza un valor medio de 2063mi con una desviación estándar no detectable. Y una diferencia de 2060mi sobre el estado sin estrés.\\


\vspace{\baselineskip}
\par Con el resultado se puede observar el aumento sustancial del uso de la memoria RAM, por lo cual esta funcionando correctamente la inyección de fallas.\\



\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficaspruebas/usoram.png}
	\caption{Gráfica del uso de memoria RAM en un pod en función del tiempo durante el experimento.}
	\label{fig:usoram01}
\end{figure}

\subsubsection{Probando el estrés por disco}

\carlos{Aqui hace falta una grafica que muestre el uso del disco  funcion del tiempo, en un estado normal}
\carlos{Aqui hace falta una grafica que muestra el uso del disco en funcion del tiempo mientras se ejecuta el fault injection}
\thomas{Agregado}

\par Es importante medir el disco ya que el rendimiento de un computador depende en gran medida de él. El tiempo que tarda en arrancar, en apagarse, en iniciarse una aplicación o en transferir un archivo, son parámetros que pueden pasar a medir mucho mas tiempo si el disco duro no esta en un estado óptimo.\\

% \par Se probara la inyección de falla estudiando el porcentaje de escritura y lectura inicial del disco (antes del estrés) de un pod de Nginx, luego se estresara al agregarle muchas operaciones al disco y por ultimo se observara el estado (mientras sucede la falla) para compararlo con el inicial y así demostrar que esta funcionando dicha falla.\\

\par Para obtener el indicador en porcentaje en cada estado, se utilizo el comando \\ \verb+iostat -dxy 2 1 | awk '/sda/{print $NF}'+ desde el pod donde se ejecuto la prueba, dicho comando básicamente nos mostrara el porcentaje de escritura y lectura del disco sda.\\

%-dxy es estadisticas ampliadas (-x) por dispositivos (-d) omitiendo el primer reporte desde el arranque del sistema (y), 2 seg de espera 1 repeticion y mandamos a imprimir la ultima columna de la fila de sda.  

% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & E/S Disco(porcentaje)\\
%  \hline
%  Inicial & 1.00\\
%  Falla & 96.80\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del porcentaje de E/S del disco en los estados del experimento de estrés por disco.}
% \label{tab:tabla44}
% \end{table}

\par En la Figura \ref{fig:usodico01} se presenta la variación del porcentaje de operaciones de entrada y salida del disco en función del tiempo. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla de disco. El sistema fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. A diferencia de las otras fallas anteriormente consideradas (CPU, latencia y RAM), la falla correspondiente a disco no muestra un comportamiento estable durante el tiempo de ejecución del estrés. Ella parece indicar una tendencia lineal con pendiente negativa y expresar un decaimiento en el tiempo del estrés considerado. En esta etapa el porcentaje de uso de disco alcanza un valor medio de 91.24\% con una desviación estándar igual a 9.54. Y una diferencia de 90.24\% sobre el estado sin estrés.\\


\par Con el resultado se puede observar el aumento sustancial de las operaciones de escritura y lectura en el disco, por lo cual esta funcionando correctamente la inyección de fallas.\\

 

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficaspruebas/usodisco.png}
	\caption{Gráfica del porcentaje de uso del disco por un pod en función del tiempo durante el experimento.}
	\label{fig:usodico01}
\end{figure}

\section{Evaluacion del sistema de fallas en un entorno de Kubernetes}

\carlos{Cada experimento debe llevar una grafica en funcion del tiempo (duracion del experimento) donde se pueda apreciar el comportamiento habitual y el fallo que estan inyectando}.
\thomas{Agregado}

\carlos{que criterio están utilizando para generar ese "trafico", sobrecarga, o latencia?}
\thomas{solicitudes desde el navegador, el eje Y de cada punto en las gráficas es el tiempo que dura en responder Nginx al navegador}

\par Una vez desarrollado el sistema de inyección de fallas, se realizaron varios experimentos para estudiar el comportamiento de Kubernetes al sufrir las fallas consideradas. En esta sección se explican los experimentos realizados y se ilustran los resultados obtenidos.\\

\label{sec:medicion}
\par Se midió el desempeño del sistema haciendo uso del tiempo de solicitud el cual es la duración total empleada por Nginx para procesar una solicitud y se expresa en segundos. Dicha métrica permitió comparar los resultados obtenidos utilizando distintos casos de prueba.\\


% \par Esta sección se dividirá en dos partes, la primera en la que se estudiara el correcto funcionamiento de las inyecciones de fallas y la segunda parte en la que se observara y analizará el comportamiento de Kubernetes al sufrir fallas en sus pods.\\


% \subsection{Experimentos del comportamiento de Kubernetes}

% \par En el grupo de experimentos a continuación se busca estudiar el comportamiento de Kubernetes ante fallas.\\ 

\par Se preparo un pod de Nginx que sirvió un documento HTML que ocupa 16.8 MB de espacio en disco, a su vez Nginx esta configurado para almacenar los logs de acceso en el cual registramos la métrica de tiempo de solicitud, dicha variable se utilizo para representar el tiempo en segundos que tardo procesar la solicitud y así se estudio el rendimiento durante una falla.\\

\par Se creo un servicio de Kubernetes que sirvió dos replicas del pod anteriormente descrito para comprobar si Kubernetes pedía realizar correctamente el balanceo de carga.\\

\par Cabe destacar que todos los experimentos de esta sección se realizaron en una maquina virtual que utiliza un disco HDD, con dos cores de CPU y 4GB de RAM.\\

\par Previo a realizar cualquier test o caso, se determino una metrica inicial sobre los pods, lo cual proporciono el siguiente valor promedio del tiempo de solicitud (rt).

\begin{table}[ht!]
\centering
\caption{Tiempo de Solicitud inicial.}
\vspace{0.5\baselineskip}
\begin{tabular}{ |c|c| } 
 \hline
 \multicolumn{2}{|c|}{Estado inicial} \\
 \hline
 \hline
 Tiempo de Solicitud & Valor Promedio Inicial\\
 \hline
 Request Time (rt) & 0.49 s\\
 \hline
\end{tabular}
\label{tab:tabla406}
\end{table}

\subsubsection{Caso \#1: Falla de CPU en una replica}
\label{sec:falla_cpu_exp}
\carlos{como han medido el rendimiento? en funcion del tiempo de respuesta de la aplicacion? que aplicacion está funcionando?}
\thomas{si, lo estamos midiendo en función del tiempo de respuesta, puede ver una explicación de esto \hyperref[sec:medicion]{AQUI (hacer click)}; el servicio web que esta funcionando se explica \hyperref[sec:servicio_web]{AQUI (hacer click)}}


\par Se inyecto la falla de CPU en una replica durante 5 minutos, a continuación el resultado en el rendimiento del servicio.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficasexperimentos/CPU1.png}
	\caption{Gráfica de variación temporal del tiempo de solicitud del servicio para la falla de CPU en una r\'eplica.}
	\label{fig:cpu01}
\end{figure}

\par En la Figura \ref{fig:cpu01} se muestra la variación temporal del tiempo de solicitud del servicio. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla. El servicio fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. Una vez inicializada la falla se mide un aumento en el tiempo de solicitud el cual tiene un valor promedio de 0.87 con una desviación estándar igual a 0.17. Y una diferencia de 0.38 sobre el estado sin estrés.\\


\par Se observ\'o que Kubernetes logro hacer un balanceo de carga ya que la replica que respondió las solicitudes no fue la que se encontraba afectada con la falla del CPU, sin embargo, se pudo notar un leve aumento en el tiempo de solicitud porque el CPU del nodo se vio comprometido con la falla.\\



% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Tiempo de solicitud(segundos)\\
%  \hline
%  Inicial & 0.492\\
%  Falla & 1.300\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del tiempo de solicitud en los estados del caso \#1.}
% \label{tab:tabla45}
% \end{table}


\subsubsection{Caso \#2: Falla de CPU en dos replicas}

\par Se inyecto la falla de CPU en las dos replicas durante 5 minutos, a continuación el resultado en el rendimiento del servicio.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficasexperimentos/CPU2.png}
	\caption{Gráfica de variación temporal del tiempo de solicitud del servicio para la falla de CPU en dos r\'eplicas.}
	\label{fig:cpu02}
\end{figure}

% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Tiempo de solicitud(segundos)\\
%  \hline
%  Inicial & 0.492\\
%  Falla & 10.037\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del tiempo de solicitud en los estados del caso \#2.}
% \label{tab:tabla46}
% \end{table}

\par En la Figura \ref{fig:cpu02} se muestra la variación temporal del tiempo de solicitud del servicio. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla. El servicio fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. Una vez inicializada la falla se mide un aumento en el tiempo de solicitud el cual tiene un valor promedio de 7.76 con una desviación estándar igual a 4.53. Y una diferencia de 7.27 sobre el estado sin estrés.\\

\par El comportamiento de la respuesta del sistema parece mostrar dos etapas: i) una inicial de aumento leve, continuo y sostenido, seguido de una disminución en iguales términos, y ii) otra después de variaciones positivas y negativas abruptas.\\

\par Se pudo observar un aumento considerable del tiempo de solicitud, Kubernetes repartió el total del CPU disponible entre las 2 replicas, cada una con un uso aproximado de 850 mCPU (un total entre ambas de aproximadamente 1650) sin embargo esto no resuelve la falla simplemente realizo un balanceo del recurso en el nodo. Aunque esta falla afecto en promedio mucho mas al rendimiento del servicio que en el caso anterior (en una solo replica), en ambas se puede notar un comportamiento de picos, se tiene la hipótesis que esto es debido a la cola de procesos en el CPU que a veces prioriza al servicio por lo cual los tiempos de solicitud disminuyen abruptamente en ciertos puntos. \\



\subsubsection{Caso \#3: Falla de disco en una replica}

\par Se inyecto la falla de disco en una replica durante 5 minutos, a continuación el resultado en el rendimiento del servicio.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficasexperimentos/Disco1.png}
	\caption{Gráfica de variación temporal del tiempo de solicitud del servicio para la falla de disco en una r\'eplica.}
	\label{fig:disco01}
\end{figure}


% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Tiempo de solicitud(segundos)\\
%  \hline
%  Inicial & 0.492\\
%  Falla & 1.900\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del tiempo de solicitud en los estados del caso \#3.}
% \label{tab:tabla47}
% \end{table}

\par En la Figura \ref{fig:disco01} se muestra la variación temporal del tiempo de solicitud del servicio. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla. El servicio fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. Una vez inicializada la falla se mide un aumento en el tiempo de solicitud el cual tiene un valor promedio de 3.17 con una desviación estándar igual a 0.42. Y una diferencia de 2.68 sobre el estado sin estrés.\\

\par El comportamiento de la respuesta del sistema parece indicar un aumento lento y sostenido durante los primeros 1.5 minutos de estrés hasta alcanzar una especie de saturación, o sea, un valor algo estable y continuo en el tiempo.\\

\par Se pudo notar que Kubernetes respondió las solicitudes con ambas replicas (la que poseía la falla y la que no, es decir, no hubo balanceo en esta falla), en ambas replicas se pudo notar un leve aumento en el tiempo de solicitud ya que ambas replicas comparten el mismo disco del nodo, cabe destacar que cada pod tiene su propio volumen y solo al volumen de la replica que esta siendo afectada por la falla es el que se encuentra bajo estrés. \\



\subsubsection{Caso \#4: Falla de disco en dos replicas}


\par Se inyecto la falla de disco en las dos replicas durante 5 minutos, a continuación el resultado en el rendimiento del servicio.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficasexperimentos/Disco2.png}
	\caption{Gráfica de variación temporal del tiempo de solicitud del servicio para la falla de disco en dos r\'eplicas.}
	\label{fig:disco02}
\end{figure}



% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Tiempo de solicitud(segundos)\\
%  \hline
%  Inicial & 0.492\\
%  Falla & 3.700\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del tiempo de solicitud en los estados del caso \#4.}
% \label{tab:tabla48}
% \end{table}

\par En la Figura \ref{fig:disco02} se muestra la variación temporal del tiempo de solicitud del servicio. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla. El servicio fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. Una vez inicializada la falla se mide un aumento en el tiempo de solicitud el cual tiene un valor promedio de 3.26 con una desviación estándar igual a 1.76. Y una diferencia de 2.77 sobre el estado sin estrés.\\

\par El comportamiento de la respuesta del sistema parece indicar dos picos abruptos (subidas y bajadas de la respuesta) bien definidas.\\

\par Se pudo observar que el aumento del tiempo de solicitud fue el mas bajo en comparación a las demás pruebas en las que se estresaban ambos pods al mismo tiempo, ambas replicas dieron respuesta a las solicitudes, Kubernetes no se pudo recuperar de esta falla durante el tiempo que duro el experimento.\\

\subsubsection{Caso \#5: Falla por latencia en una replica}

\par Se inyecto la falla de latencia con 500ms en una replica durante 5 minutos, a continuación el resultado en el rendimiento del servicio.\\



\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficasexperimentos/latencia1.png}
	\caption{Gráfica de variación temporal del tiempo de solicitud del servicio para la falla de red por incremento de latencia en una r\'eplica.}
	\label{fig:latencia01}
\end{figure}

% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Tiempo de solicitud(segundos)\\
%  \hline
%  Inicial & 0.492\\
%  Falla & 0.820\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del tiempo de solicitud en los estados del caso \#5.}
% \label{tab:tabla49}
% \end{table}

\par En la Figura \ref{fig:latencia01} se muestra la variación temporal del tiempo de solicitud del servicio. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla. El servicio fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. Una vez inicializada la falla se mide un tiempo de solicitud el cual tiene un valor promedio de 0.51 con una desviación estándar igual a 0.03. Y una diferencia de 0.02 sobre el estado sin estrés.\\

\par Se pudo observar que Kubernetes logro hacer un balanceo de carga ya que la replica que respondió las solicitudes no fue la que se encontraba con latencia inyectada, dicha replica sin fallas no se vio afectada por el estrés que se le realizo a su replica hermana, no hubo un incremento significativo en el tiempo de respuesta del servicio debido al balanceo.\\


\subsubsection{Caso \#6: Falla por latencia en las dos replicas}

\par Se inyecto la falla de latencia con 500ms en dos replicas durante 5 minutos, a continuación el resultado en el rendimiento del servicio.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficasexperimentos/latencia2.png}
	\caption{Gráfica de variación temporal del tiempo de solicitud del servicio para la falla de red por incremento de latencia en dos r\'eplicas.}
	\label{fig:latencia02}
\end{figure}

% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
% \hline
% \multicolumn{2}{|c|}{Resultado} \\
% \hline
% \hline
% Estado & Tiempo de solicitud(segundos)\\
% \hline
% Inicial & 0.492\\
% Falla & 6.820\\
% \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del tiempo de solicitud en los estados del caso \#6.}
% \label{tab:tabla50}
% \end{table}

\par En la Figura \ref{fig:latencia02} se muestra la variación temporal del tiempo de solicitud del servicio. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla. El servicio fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. Una vez inicializada la falla se mide un aumento en el tiempo de solicitud el cual tiene un valor promedio de 9.91 con una desviación estándar igual a 2.73. Y una diferencia de 9.42 sobre el estado sin estrés.\\

\par El comportamiento de la respuesta del sistema parece indicar dos picos (subidas y bajadas de la respuesta) anchos bien definidos. \\

\par Se pudo observar un aumento considerable del tiempo de solicitud, ambas replicas se encontraban afectadas con 500ms de latencia, Kubernetes no se pudo recuperar de esta falla durante el tiempo que duro el experimento.\\


\subsubsection{Caso \#7: Falla de memoria RAM en una replica}

\par Se inyecto la falla de memoria RAM en una replica durante 5 minutos, a continuación el resultado en el rendimiento del servicio.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficasexperimentos/RAM1.png}
	\caption{Gráfica de variación temporal del tiempo de solicitud del servicio para la falla de memoria RAM en una r\'eplica.}
	\label{fig:ram01}
\end{figure}

% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Tiempo de solicitud(segundos)\\
%  \hline
%  Inicial & 0.492\\
%  Falla & 1.592\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del tiempo de solicitud en los estados del caso \#7.}
% \label{tab:tabla51}
% \end{table}

\par En la Figura \ref{fig:ram01} se muestra la variación temporal del tiempo de solicitud del servicio. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla. El servicio fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. Una vez inicializada la falla se mide un aumento en el tiempo de solicitud el cual tiene un valor promedio de 1.12 con una desviación estándar igual a 0.20. Y una diferencia de 0.63 sobre el estado sin estrés.\\

\par Se observ\'o que Kubernetes logro hacer un balanceo de carga ya que la replica que respondió las solicitudes no fue la que se encontraba afectada con la falla del CPU, sin embargo, se pudo notar un leve aumento en el tiempo de solicitud porque la memoria RAM del nodo se vio comprometido con la falla.\\

\subsubsection{Caso \#8: Falla de memoria RAM en dos replicas}

\par Se inyecto la falla de memoria RAM en las dos replicas durante 5 minutos, a continuación el resultado en el rendimiento del servicio.\\

\begin{figure}[htpb!]
	\centering
	\includegraphics[width=0.95\columnwidth]{images/graficasexperimentos/RAM2.png}
	\caption{Gráfica de variación temporal del tiempo de solicitud del servicio para la falla de memoria RAM en dos r\'eplicas.}
	\label{fig:ram02}
\end{figure}

% \begin{table}[ht!]
% \begin{center}
% \begin{tabular}{ |c|c| } 
%  \hline
%  \multicolumn{2}{|c|}{Resultado} \\
%  \hline
%  \hline
%  Estado & Tiempo de solicitud(segundos)\\
%  \hline
%  Inicial & 0.492\\
%  Falla & 4.164\\
%  \hline
% \end{tabular}
% \end{center}
% \caption{Tabla comparativa del tiempo de solicitud en los estados del caso \#8.}
% \label{tab:tabla52}
% \end{table}

\par En la Figura \ref{fig:ram02} se muestra la variación temporal del tiempo de solicitud del servicio. Las líneas verticales en rojo muestran los tiempos de lanzamiento y finalización de la falla. El servicio fue monitoreado durante 11 minutos, de ellos 3 minutos corresponden a antes del lanzamiento de la falla y otros 3 minutos después de finalizado el estrés. Una vez inicializada la falla se mide un aumento en el tiempo de solicitud el cual tiene un valor promedio de 6.36 con una desviación estándar igual a 4.21. Y una diferencia de 5.87 sobre el estado sin estrés.\\

\par Se pudo observar un aumento considerable del tiempo de solicitud, cada replica poseía entre 1700 y 2000 MiB de uso de memoria, ninguna de las dos replicas alcanzo los 2048 mínimos de la falla, otro dato a destacar es que el total de uso de memoria entre ambos no supero los 4096 MiB total del nodo, Kubernetes no se pudo recuperar de esta falla durante el tiempo que duro el experimento. A su vez se observaron notificaciones de procesos encargados de inyectar fallas dentro de los pods, informando que dichos procesos estaban siendo eliminados por el sistema operativo del nodo, debido al evento OOM (\textit{Out of Memory}). Aunque esta falla afecto en promedio mucho mas al rendimiento del servicio que en el caso anterior (en una solo replica), en ambas se puede notar un comportamiento de picos, se tiene la hipótesis que esto es debido al los procesos de balanceos de carga del propio sistema operativo y al aprovechamiento del espacio swap, con lo cual a veces se prioriza al servicio y así los tiempos de solicitud disminuyen abruptamente en ciertos puntos. \\

